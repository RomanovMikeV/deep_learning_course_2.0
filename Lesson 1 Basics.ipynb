{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  5   6   7   8\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- tensor\n",
      "torch.Size([3, 4]) <- tensor size\n",
      "3 <- dimension size\n",
      "\n",
      "  6   7\n",
      " 10  11\n",
      "[torch.FloatTensor of size 2x2]\n",
      " <- slicing support\n"
     ]
    }
   ],
   "source": [
    "# Создаем тензор\n",
    "x = torch.rand([3, 4])\n",
    "x = torch.zeros([3, 4])\n",
    "x = torch.ones([3, 4, 3])\n",
    "\n",
    "# print x\n",
    "#x = torch.eye(3, 4)\n",
    "\n",
    "x = torch.Tensor(\n",
    "[[1,  2,  3,  4],\n",
    " [5,  6,  7,  8],\n",
    " [9, 10, 11, 12]])\n",
    "\n",
    "print x, '<- tensor'\n",
    "print x.size(), '<- tensor size'\n",
    "print x.size(0), '<- dimension size'\n",
    "print x[1:, 1:3], '<- slicing support'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- shallow copy\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "  1   2   3   4\n",
      "  2   2   2   2\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- deep copy\n"
     ]
    }
   ],
   "source": [
    "# Копирование (по ссылке и глубокое)\n",
    "y = x\n",
    "\n",
    "y[1, :] = 1\n",
    "print x, y, '<- shallow copy'\n",
    "\n",
    "y = x.clone()\n",
    "y[1, :] = 2\n",
    "print x, y, '<- deep copy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2   4   6   8\n",
      "  3   3   3   3\n",
      " 18  20  22  24\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "   1    4    9   16\n",
      "   2    2    2    2\n",
      "  81  100  121  144\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 1.0000  1.0000  1.0000  1.0000\n",
      " 0.5000  0.5000  0.5000  0.5000\n",
      " 1.0000  1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 0  0  0  0\n",
      "-1 -1 -1 -1\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 0  0  0  0\n",
      " 1  1  1  1\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "   1    4    9   16\n",
      "   1    1    1    1\n",
      "  81  100  121  144\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 1.0000e+00  4.0000e+00  2.7000e+01  2.5600e+02\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      " 3.8742e+08  1.0000e+10  2.8531e+11  8.9161e+12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- basic math\n",
      "484.0\n"
     ]
    }
   ],
   "source": [
    "# Математические операции (стандартные поэлементные)\n",
    "print x + y, x * y, x / y, x - y, \n",
    "print x % y, x**2, x**y, '<- basic math'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.7183e+00  7.3891e+00  2.0086e+01  5.4598e+01\n",
      " 2.7183e+00  2.7183e+00  2.7183e+00  2.7183e+00\n",
      " 8.1031e+03  2.2026e+04  5.9874e+04  1.6275e+05\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.0000  0.6931  1.0986  1.3863\n",
      " 0.0000  0.0000  0.0000  0.0000\n",
      " 2.1972  2.3026  2.3979  2.4849\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8415  0.9093  0.1411 -0.7568\n",
      " 0.8415  0.8415  0.8415  0.8415\n",
      " 0.4121 -0.5440 -1.0000 -0.5366\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Более сложные операции\n",
    "print torch.exp(x)\n",
    "print torch.log(x)\n",
    "print torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4\n",
      "  9\n",
      " 10\n",
      " 11\n",
      " 12\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "\n",
      " 0  0  0  1\n",
      " 0  0  0  0\n",
      " 1  1  1  1\n",
      "[torch.ByteTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Логические операции\n",
    "y = x[x > 3]\n",
    "print(y)\n",
    "y = (x > 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.cuda.FloatTensor of size 3x4 (GPU 0)]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.cuda.DoubleTensor of size 3x4 (GPU 0)]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.cuda.IntTensor of size 3x4 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Переопределение типа\n",
    "x = x.float()\n",
    "print x\n",
    "x = x.double()\n",
    "print x\n",
    "x = x.int()\n",
    "print(x)\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "\n",
      " 1  2  3  4\n",
      " 4  3  2  1\n",
      "[torch.LongTensor of size 2x4]\n",
      "\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Взаимодействие с Numpy\n",
    "x = numpy.array([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print x\n",
    "x = torch.from_numpy(x)\n",
    "print x\n",
    "x = x.numpy()\n",
    "print x\n",
    "x = torch.from_numpy(x).float().int().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.cuda.FloatTensor of size 3x4 (GPU 0)]\n",
      " <- CUDA Tensor!\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "0.000806093215942 <- CPU time\n",
      "0.00588822364807 <- GPU time\n",
      "\n",
      "   100.0000    400.0000    899.9999   1600.0000\n",
      "   100.0000    100.0000    100.0000    100.0000\n",
      "  8100.0000  10000.0010  12100.0010  14399.9990\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Перемещение на GPU\n",
    "import time\n",
    "x_cuda = x.cuda()\n",
    "print x_cuda, '<- CUDA Tensor!'\n",
    "print x\n",
    "start = time.time()\n",
    "y = (x - x + x*10.0) ** 2\n",
    "print time.time() - start, '<- CPU time'\n",
    "start = time.time()\n",
    "y_cuda = (x_cuda - x_cuda + x_cuda * 10.0) ** 2\n",
    "print time.time() - start, '<- GPU time' \n",
    "y = y_cuda.cpu()\n",
    "print y\n",
    "# print(x ** 2, '<- operation performed on the GPU!!!')\n",
    "# print x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "Variable containing:\n",
      "  2   4   6   8\n",
      "  2   2   2   2\n",
      " 18  20  22  24\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- gradient\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое (символьное) дифференциирование (обратное распространение градиента) (случай скаляра)\n",
    "import torch.autograd\n",
    "print x\n",
    "x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "formula = (x_var ** 2).sum()\n",
    "formula.backward()\n",
    "\n",
    "print x_var.grad, '<- gradient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    7.3891    54.5982   403.4288  2980.9578\n",
      " 2980.9578   403.4288    54.5982     7.3891\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "Variable containing:\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "Variable containing:\n",
      "   14.7781   109.1963   806.8576  5961.9155\n",
      " 5961.9155   806.8576   109.1963    14.7781\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое дифференциирование (обратное распространение градиента) (случай тензора)\n",
    "# variable -> formula1 (вектор) -> formula2 (скаляр)\n",
    "x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "formula1 = torch.exp(x_var) ** 2.0\n",
    "y_var = torch.autograd.Variable(formula1.data.clone(), requires_grad=True)\n",
    "formula2 = y_var.sum()\n",
    "formula2.backward()\n",
    "y_grad = y_var.grad.clone()\n",
    "print formula1\n",
    "print y_grad\n",
    "formula1.backward(gradient=y_grad.data)\n",
    "print x_var.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Написать и вычислить бинарную кросс-энтопию для векторов target и probs при помощи средств pytorch.\n",
    "Бинарная кросс-энтропия вычисляется:\n",
    "\n",
    "$$BCE(t, p) = - \\sum_i t_i \\log(p_i) + (1 - t_i) \\log(1 - p_i)$$\n",
    "\n",
    "target = (0, 0, 0, 0, 1, 1, 1, 1)\n",
    "probs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "\n",
    "Какой из элементов суммы дает наибольший вклад в функцию потерь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "\n",
    "Логистическая регрессия минимизирует функцию бинарная кросс-энтропия BCE, предполагая, что\n",
    "$$p_i = \\sigma (< w_i, x_i >)$$\n",
    "где $w_i$ -- веса свойств объектов, $x_i$ -- свойства объектов. Пусть $\\vec{x} = (1, x_1, x_2)$. Подставить вероятности в выражение $BCE$ и найти производную $BCE$ по весам.\n",
    "Вычислить производную в случае двух объектов (любым способом, можно посчитать руками, можно написать скрипт):\n",
    "\n",
    "$t = 1, x = (1, 1, 1)$\n",
    "$t = 0, x = (1, 0, 1)$\n",
    "\n",
    "В точке w = (0, 0, 0).\n",
    "\n",
    "Совпадает ли результат явного вычисления с результатом работы функции backward?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Средствами pytorch реализовать алгоритм градиентного спуска.\n",
    "\n",
    "При помощи этого алгоритма найти минимум функций:\n",
    "$x^2 + y^2$ с начальным приближением $x_0 = 10, y_0 = 5$, \n",
    "\n",
    "$0.5 \\log x + 0.5 \\log (1 - x)$ с начальным приближением $x_0 = 0.9$, \n",
    "\n",
    "$x^2 + 10 y^2 + 2xy$, с начальным приближением $x_0 = 10.0, y_0 = 10.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "\n",
    "При помощи алгоритма градиентного спуска оптимизировать вектор probs при фиксированном векторе target из задания 1.\n",
    "Рассмотреть два варианта решения задачи: \n",
    "\n",
    "1) при помощи CPU \n",
    "\n",
    "2) при помощи GPU\n",
    "\n",
    "Получилось ли ускорить процесс при помощи GPU? Обсудить, почему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "О градиентном спуске:\n",
    "https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
